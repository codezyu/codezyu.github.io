# kernel
在异构设备中包括(FPGA) kernel表示为加速器编写的代码，代表一个计算任务， kernel函数会被声明为

```
<<<gridDim, blockDim, shared_memory_size, stream>>>
```

网格（Grid）是最高层次的并行执行概念。简单来说，它代表了你所有 GPU 线程的集合。
- 三维，方便进行逻辑映射（向量 - 一维）
- 硬件会把所有线程都调度到一维的流处理器上，但网格的维度配置会影响你的并行任务
	- **线程块**的线程总数是有限制的
	- 在处理一个 2D 矩阵时，使用 2D 网格可以更容易地让相邻的线程访问相邻的内存地址，这有助于实现**内存合并（memory coalescing）**，从而提高性能。
块是比线程（Thread）更高一级的组织单元。你可以把一个块看作是 **CUDA 线程的基本管理单位**。每个块都拥有自己的一块**共享内存（shared memory）**。这块内存是块内所有线程都能访问的快速片上存储器
每个块在整个网格（Grid）中都有一个唯一的 ID。在启动内核时，你可以通过 `blockIdx` 变量来获取这个 ID。`blockIdx.x`、`blockIdx.y` 和 `blockIdx.z` 分别代表块在三维网格中的坐标。

一个网格中的所有块会被 CUDA 调度器分配到可用的 SM 上。一个 SM 可以一次处理一个或多个块。在一个 SM 上，块内的线程会被进一步组织成 **Warp（线程束）**，这是 GPU 硬件调度的基本单位。
**SM** 是 **Streaming Multiprocessor**（流式多处理器）的缩写，一个完整的 GPU 芯片由多个 SM 组成。例如，一个高端 GPU 可能有几十甚至上百个 SM，而每个 SM 内部又包含了多个更小的计算单元。


CUDA 流是一个任务队列，它允许你并行地执行多个操作，例如同时进行数据传输和内核计算。如果你省略这个参数，内核将默认在**默认流**（stream 0）上执行，默认流是同步的。


这个线程会被打包成一个包含 32 个线程的 Warp，由 GPU 硬件进行调度。尽管硬件为一个完整的 Warp 准备了资源，但实际上只有 1 个线程在工作。

