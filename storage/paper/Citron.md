Header:

论文出处：FAST '23。本文指出在分布式存储系统中，随着网络带宽的提升（如 NVIDIA ConnectX-6 达到 215 Mops/s），现有的基于 RPC 的中心化范围锁管理机制面临严重的服务器端 CPU 瓶颈，导致吞吐量受限且长尾延迟显著增加 11。

# 问题

- **原有方案的不适应性**
    
    - 现有分布式范围锁管理器（DRLMs）依赖中心化的服务器端 CPU 通过 RPC 接口处理锁请求 2222。
        
    - 高网络包率与有限 CPU 资源之间存在错配，导致吞吐量瓶颈 33。
        
    - RPC 范式导致请求在 RNIC 和 CPU 处排队，在高并发下产生极高的排队延迟（例如 p99 延迟可达 4-5 个网络往返时间，即 RTT） 4444。
        
    - 简单的去中心化方案（如将范围分割为固定大小的段并关联互斥锁）在处理非对齐或动态大小的范围请求时，会导致严重的“假冲突”（false conflicts），吞吐量下降 92% 且尾延迟增加 5.65 倍 5。
        
- **底层开销分析**
    
    - **动态数据结构遍历开销**：现有方案（如 Lustre 中的 interval trees）在锁操作时需要 CPU 遍历和修改复杂的动态数据结构，消耗大量 CPU 周期，影响同一服务器上其他计算密集型服务的性能 6666。
        
    - **RDMA 语义限制**：RDMA 缺乏对动态远程内存分配的支持，使得直接移植现有基于动态结构（如链表、树）的 DRLM 变得困难 7。
        
    - **指针追逐（Pointer Chasing）的网络放大**：如果简单地用 RDMA 实现传统数据结构（如链表），每一次内存访问都会转化为一次网络往返（RTT）。在锁操作路径上，这种多次 RTT 会完全掩盖 RDMA 的性能优势 8888。
        

# 解决方案 (The Solutions)

## 基于静态线段树的零拷贝设计

为了规避服务器端 CPU 参与，CITRON 摒弃了动态的区间树，转而采用一种对 RDMA 友好的静态数据结构——线段树（Segment Tree） 9。CITRON 将线段树展平为数组，通过节点索引算术即可进行树的导航，无需指针 10。

- **机制拆解**：
    
    - **物理布局**：树节点被放置在连续的内存数组中。对于索引为 $x$ 的节点，其父节点为 $\lfloor(x+2)/4\rfloor$，第 $i$ 个子节点为 $4x-2+i$ 11。
        
    - **节点格式**：
        
        - **叶子节点**：使用 64 位的 Bitmap，每一位代表一个存储单元。客户端使用 RDMA Masked-CAS 原子操作来设置或清除位 12。
            
        - **内部节点**：包含 `Exp`（扩展标志）、`Occ`（占用标志）以及两对计数器 `{TCnt, TMax}` 和 `{DCnt, DMax}`。客户端使用 RDMA Masked-FAA 操作这些字段 13。这两对计数器分别实现了 Lamport 面包房算法（Bakery Algorithm）的变体，用于当前节点和后代节点的并发控制 14141414。
            

<img src="" alt="image" width=100% />

> Researcher's Comment:
> 
> 这一步设计的核心在于“用空间换可寻址性”。传统的区间树虽然空间紧凑，但依赖指针和动态内存分配，这对单边 RDMA 是致命的。CITRON 选用线段树（Segment Tree）并将其映射为静态数组，本质上是将逻辑上的树形结构转化为了物理上可通过简单的算术公式直接计算偏移量（Offset）的线性空间。这使得客户端完全不需要服务器 CPU 的辅助就能定位任何锁节点，彻底解耦了 CPU 与网络操作。

## 基于“中间相遇”（Meet-in-the-Middle）的锁协议

CITRON 设计了一套紧密结合 RDMA 语义的锁获取协议，将锁冲突的解决简化为祖先节点与后代节点之间的通信 15。

- **机制拆解**：
    
    - **范围映射（Step 1）**：客户端在本地计算，将请求的范围 $[l, r)$ 拆分为 $O(\log N)$ 个树节点。为了平衡延迟和假冲突，CITRON 通过背包算法选择最多 $k$ 个节点（实现中 $k=2$）来覆盖请求范围 16161616。
        
    - **锁获取流程（Step 2）**：
        
        - **(a) 锁定内部节点**：使用 RDMA Masked-FAA 执行类似面包房算法的操作，获取 Ticket 并轮询等待 17。
            
        - **(b) 检查祖先**：读取并检查所有祖先节点的 `Occ` 标志，确保没有被上层锁占用 18。
            
        - **(c) 占据/锁定当前节点**：如果是叶子节点，用 Masked-CAS 锁定；如果是内部节点，设置 `Occ` 标志以阻塞后来的后代节点锁请求 19191919。
            
        - **(d) 中间相遇同步（MITM）**：这是协议的精髓。为了避免通过网络遍历所有后代节点（数量呈指数级），CITRON 引入了参数 $m$。客户端通知当前节点的第 $m$ 层祖先，并检查当前节点向下 $m$ 层内的后代节点 20。
            
    - **时间窗口等待**：为了保证正确性，客户端需要等待 $T_{wait}$ 时间，确保与冲突的客户端（Bob）在时间轴上有交集，能够互相检测到对方的状态 21212121。
        

> Researcher's Comment:
> 
> 这个协议最精妙的地方在于解决了范围锁中“牵一发而动全身”的难题。在一个树状结构中，锁住一个节点不仅影响它自己，还隐含地锁住了所有的子树和祖先路径。如果让客户端去检查所有子孙节点，网络开销是 $O(4^h)$，这是不可接受的。CITRON 的 MITM 策略巧妙地利用了“通知祖先”和“检查后代”的不对称性，强制冲突双方在树的某一层级“相遇”。配合基于有界时钟漂移（Clock Drift）的 $T_{wait}$ 等待机制，它在无锁（Lock-free）的异步网络环境中实现了强一致性，这在分布式并发控制设计中是非常高级的权衡（Trade-off）。

## 运行时动态扩容

尽管使用了静态数据结构，CITRON 仍支持运行时扩容以适应存储规模的增长 22。

- **机制拆解**：
    
    - **最大值检测**：利用 `Maximizer` 变量，客户端通过 RDMA Masked-CAS 尝试更新最大访问边界，从而检测越界请求 23。
        
    - **自相似性扩容**：利用线段树的自相似性（Self-similarity），将旧的小树视为新大树的一个子树。客户端通过 RPC 请求服务器仅分配新增加的内存区域（这是唯一需要服务器 CPU 介入的地方，且频率极低），然后更新元数据服务 24242424。
        
    - **并发处理**：扩容期间，通过设置旧树根节点的 `Exp` 标志来通知并发的锁请求者进行重试，保证了扩容过程的安全性 25252525。
        

# 核心亮点 (Key Insights & Trade-offs)

- **硬件感知的算法设计**：CITRON 的锁协议并非仅仅是逻辑算法，而是深度定制于 RDMA 硬件特性。例如，利用 Masked-CAS 的位操作能力来管理叶子节点的 Bitmap，利用 Masked-FAA 来原子更新计数器，从而避免了多次 round-trip。
    
- **有限的同步成本**：通过 MITM 设计，无论锁请求位于树的哪一层，同步成本都接近常数级。在最佳情况下（Fast Path），获取锁仅需两个 RDMA RTT 26262626。
    
- **假冲突与延迟的权衡**：CITRON 允许客户端用最多 $k$ 个节点来近似覆盖请求范围。增加 $k$ 可以减少覆盖了但未被请求的区域（即减少假冲突），但会增加需要获取的锁数量（即增加延迟）。论文发现 $k=2$ 是一个极佳的平衡点，既消除了大部分假冲突，又保持了低延迟 27272727。
    
- **无服务器 CPU 介入的极致扩展性**：除了极其罕见的扩容操作，所有的锁获取和释放路径完全绕过了服务器 CPU。这意味着系统的锁吞吐量不再受限于 CPU 核心数，而是直接受限于 RNIC 的消息处理能力，这在下一代高性能网络硬件上将表现出极高的扩展性。