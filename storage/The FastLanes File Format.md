
这篇文章由DuckDB技术人员，发表在VLDB25上，核心是实现数据的部分解码
# 背景
### 列式存储格式
### Parquet 格式
Apache Parquet 是一种列式存储文件格式，每个表列的值是挨着存储的，广泛用于hadoop，Spark等数据格式。按列存储，每个文件包含一些元数据，比如最值等等
Parquet文件在水平方向被切分为多个Row Group，每个Row Group都保存所有列的某个范围内的值，而这个范围内某一列的值就对应一个Column Chunk，一个Column Chunk由多个Page组成
### ORC数据格式

DuckDB包括这些实际上都用了这些格式

## 硬件数据并行支持
- GPU等硬件的广泛使用
- CPU有SIMD指令
# 动机
## 数据格式需要优化
- Snappy 等压缩算法数据并行不够，现有的数据格式，不能利用硬件的数据并行能力
- 解压缩后处理阶段：现有查询引擎支持compressed execution使得数据处于SIMD友好的presentation
	- 可以在保持数据压缩状态的同时直接参与向量化计算
	- 因此数据格式需要提供压缩向量，进而实现部分地解压缩
>  DuckDB, Velox and Procella
### mini_bg: 向量化查询
数据库传统上采用行式处理，一次处理一行数据，一次处理一批数据（向量），可以利用SIMD指令并行处理多个数据元素（即向量）
- 为每种压缩向量类实现专门的算术、比较、聚合等操作

## 现有的压缩算法
### HWC
Heavy-Weight Compression： 基于块，通用的，对于数据类型是无感知的，比如：
- **Snappy**：由Google开发，以**极快的压缩和解压缩速度**著称，但压缩比适中。
- **Zstd (Zstandard)**：由Facebook（现Meta）开发，提供**高性能**和**高压缩比**的平衡，通常比Snappy有更高的压缩比，且速度也很快。
优点是提供很高的压缩比例，但是CPU敏感，解压缩相当慢
### LWC
LightWeight Compression (LWC) ：基于特定的数据模式，LWC能够利用硬件的数据并行能力（比如能达到64倍）使得有可能访问压缩数据比原始数据还快，但是压缩比比较低，如果在LWC上面使用HWC压缩，能够提高压缩比，这是大量数据所需要的
LWC算法比如有

| **压缩方案**                                                     | **算法原理**                                                                                                                                                                          | **适用场景**                                                |
| ------------------------------------------------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------- |
| **FFOR** (Frame-of-Reference) **或 FOR (Frame-of-Reference)** | 找到一个数据块中**所有整数的最小值（基准值，Frame）**，然后只存储每个整数与这个基准值之间的**差值（Delta）**。因为这些差值通常都很小，可以用比原始整数少得多的位数来表示和存储。                                                                                 | 包含**大量连续、变化范围小**的整数序列的列（如列式数据库中的ID、时间戳、排序后的列）。          |
| **Delta** (Delta Encoding)                                   | 它不存储原始数据值，而是存储**每个数据值与其前一个数据值之间的差值**（Delta）。如果数据是平滑或单调递增的（如时间序列、已排序的ID），这些差值会很小，可以高效地用较少的位表示。                                                                                     | **单调递增**或**平滑变化**的序列，如时间戳或排序后的主键。                       |
| **DICT** (Dictionary Encoding)                               | **字典编码**。它将一列中**重复出现的字符串值**（或重复的整数值）提取出来，构建一个**唯一的字典**。然后，在数据列中，用**短的整数 ID**（即字典的索引）来代替原始的重复值。                                                                                    | **基数低**（Low Cardinality），即**重复值多**的字符串列（如国家名、产品类别、布尔值）。 |
| **RLE** (Run-Length Encoding)                                | **行程长度编码**。它通过存储一个**值**和该值**连续重复的次数**（行程长度）来压缩数据。例如，`AAAAABBCC` 会被压缩成 `5A2B2C`（具体编码方式不同）。**FastLanes-RLE** 是 RLE 的一个高性能变体，针对 SIMD 硬件进行了优化。                                        | **长序列重复值**的列，例如稀疏数据或已排序的列。                              |
| **ALP** (Adaptive Log-based Paired-coding)                   | 一种针对**浮点数**（尤其是时间序列数据）优化的压缩方案。它通过以下方式工作：<br>1. **去趋势化（Detrending）**：拟合一个模型（例如线性回归）来捕捉数据的宏观趋势。<br>2. **编码残差（Residuals）**：只存储原始值与模型预测值之间的**微小残差**。这些残差可以高效地用整数压缩技术（如FOR或Delta）进行编码。 | **浮点数**列，尤其是**时间序列**数据。                                 |
| **FSST** (Fast Static Symbol Table)                          | **快速静态符号表**。这是一种针对**字符串**设计的高性能压缩方案。它通过预先构建一个**静态的符号表**（Symbol Table），将输入字符串中**重复出现的短序列**（例如 1 到 8 个字节的片段）映射成一个**更短的“代码”**（通常是单个字节）。它允许**随机访问**和直接在压缩数据上进行**相等比较**。               | **高基数**和**低基数**的字符串列（通用字符串压缩），尤其是在需要随机访问和快速查询的数据库场景。    |
### 综合性算法
#### Cascading LWC schemes
链式级联地使用LWC来达到HWC的压缩比，将多个 LWC 算法（如 Delta、RLE、FOR 等）串联起来，按顺序应用于数据，比如BtrBlocks
#### Multi-Column Compression (MCC) 
多列数据可能存在关联性，来提高压缩比
- 如果一列的数据可以根据另一列的数据**推断**出来
- 拆分成多列，将包含混合数据（如 `"Compression101"`）的字符串列，拆分为字符串子列（`"Compression"`）和整数子列（`"101"`）。分别执行压缩

## 解码
### 向量化解码
意思是把压缩数据（一个向量，比如1024个数据）直接送到CPU的L1 cache，这样节省带宽，解压后的数据可以完全容纳在 L1 缓存中，减少了访存，同时也会立即处理
- 因为拷贝开销大 memcpy
- 立即处理依赖于 ultrafast auto-vectorized decoding kernels （1个周期解码60个值）性能其实可以的
BtrBlocks 依赖于旧编码，因此是没法使用的，同时全量解压，导致拷贝开销比较大
更小的数据是更利于缓存的，比如CPU的L1缓存，GPU的缓存只会更紧张
### 压缩执行
LWC对数据模式的感知这种额外信息也有利于数据引擎的执行，比如常量编码（Constant Encoding）。如果一列所有值都相同，编码会告诉查询引擎，针对该列的所有操作（如过滤、聚合）只需执行**一次**即可，而不是对所有行值都执行。
很多引擎比如DuckDB支持压缩向量允许数据随机访问（randomly accessible），但数据本身仍保持编码状态（如 DICT, FOR, FSST）。
- 比如TPCH 的 `l_tax` 列在 SQL 中定义为 `decimal(18,2)`，在内部通常用 64 位整数（int64）实现。假设实际数据值只在 0.01 到 0.08 之间（即整数 1 到 8）。应用 LWC（如 FOR + Bit-packing），只需要 3 个比特（bits）来存储每个值。这个时候可以只用8位，减少了IO和提升CPU并行执行能力
> 太恐怖的优化思路了

# 设计
## 灵活的压缩和解压缩算法
通过动机可知，LWC的组合是能够利用硬件的数据并行能力，同时提供更多的数据信息，FastLane设计了表达式编码的抽象，组合了编码和解码的优化： cascaded encoding + MCC + compressed execution + vectorized decoding
 cascaded encoding 对应的就是不同编码算法的组合，也就是编码算子的拼接，以压缩格式存储数据，并在解码时将其转换到下一个格式。这些转换源于将 LWC 分解成编码算子
 - 每个操作符一次只处理 1024 个值（一个向量），这个大小刚好能适应 CPU 的 L1 缓存。
 - 所有操作都在这 1024 个值上以紧密循环（tight loop）执行，其一致的工作模式允许编译器进行自动向量化（auto-vectorize），实现极致的并行效率
 - 
### 编码算子
<img src="https://cloudflare-imgbed-4ea.pages.dev/file/paper/database/1762012588429_image.png" alt="image.png" width=100% />

#### FFOR (Fast Frame of Reference)

FFOR 操作符用于压缩整数数据，使用一个基准值（Base）作为参考点来存储数据，即只记录原始值与这个最小基准值之间的差值。这些差值随后被进行位封装（Bit-Packed）存储，即只使用表示该差值所需的最小比特数。该操作符的创新在于将计算基准值差值和位封装/解封装操作融合（Fused）在一起，因此在解码时消除了在内存和寄存器之间进行额外的 SIMD 存储和加载步骤，从而能直接输出解封装好的整数向量。

#### PATCH

PATCH 操作符旨在提高编码对离群值（Outliers）的鲁棒性，它将不符合主编码规则的异常数据值从主向量中分离出来。它使用一个名为选择向量（SelectionVector）的结构来存储这些异常值在原始数据中的位置索引，
这个结构的设计特点是适合在并行硬件上快速查找。PATCH 在需要完全解压缩时，会利用这个选择向量将分离存储的异常值重新整合到正确的位置。

#### DELTA

DELTA 操作符专门处理整数数据，它存储的是当前值与前一个值之间的差值（Delta Values），这对于有序或趋势性数据可以实现高效压缩。为了优化性能和打破数据依赖性，它将这些差值存储在统一转置布局（UTL）中。这种特殊的布局使得 CPU 能够使用自动向量化的方式，并行计算原本必须顺序执行的差值累加，从而快速计算出原始值。

#### ALP/ALP_RD

ALP 操作符用于浮点数（DOUBLE 和 FLOAT）数据的压缩，它通过将浮点数数据映射到整数形式进行存储。ALP_RD 是它的一个变体，它将浮点数的二进制表示精确地拆分成前位（Front Bits）和尾位（Tail Bits）两部分。前位是浮点数中最重要的、变化最频繁的比特；尾位是剩余比特。前位部分被视为整数进行压缩，从而为复杂的浮点数数据带来了整数压缩算法的效率。

#### Glue

Glue 操作符的功能是合并两个来源的位封装数据，它在解码流程中被用来将 ALP_RD 拆分出来的前位和尾位重新组装在一起，以还原完整的浮点数值。此外，它也被用于重新组合来自多列压缩（MCC）方案的一对多映射数据，作为复杂编码结构中的数据重组环节。

#### DICT (Dictionary Encoding)

DICT 操作符用于压缩重复数据，它通过维护一个包含所有唯一值的字典（Dictionary）和一个存储指向该字典索引的代码向量（Vector of Codes）来进行工作。它支持对字典本身进行压缩，并且设计为只有在查询需要时才会用实际值替换代码，保证了字典内容的随机访问能力，避免了传统块式解码的限制。

#### Cast

Cast 操作符的功能是修改列的数据类型，使其不同于文件模式中指定的类型，目的是为了简化编码和加速查询执行。它常用于将宽类型转换为窄类型（如 64 位整数到 8 位整数），或将变长类型转换为定长类型（如字符串到整数），以便在查询执行时利用更小的内存占用和 SIMD 优势。

#### RLE / Cross RLE

RLE 操作符用于压缩连续重复的值，它将重复的数据映射到字典编码，并对表示行程的索引应用 Delta 编码，最终存储在一个 **UTL** 友好的格式中。Cross RLE 是它的变体，它将经典 RLE 应用于整个行组，旨在减少 FastLanes 针对每个向量 RLE 变体所引入的元数据开销，以提高长行程数据的效率。

#### FSST / FSST12

FSST 操作符用于字符串数据的压缩，它使用一个静态符号表（Static Symbol Table）将字符串中的常见字节序列替换为较短的代码。FSST12 是一个使用 12 位代码的变体，可以编码更多的符号。这两种操作符都允许对单个压缩字符串进行随机访问，支持查询直接在压缩数据上执行。


### 表达式
使用逆波兰表达式
### 局部最优表达式
算子的组合有多种，需要通过搜索来找到相对较优的表达式

## 文件存储格式
FastLanes 文件格式是一种新型列式存储格式，专门用于存储表达式编码的数据结构
## 数据划分
数据被按行划分成row group
- row group： 固定数量的record，总是1024的倍数，和ORC类似
每个row group 按列进行划分
- column chunk： 同一列上的数据连续存储
- row group的footer包含column chunk的位置信息，来跳过访问不相关的列

压缩后，按照segment划分
- entry points: segment的位置
- segment: 

# 缺陷
## 编码时间很长
