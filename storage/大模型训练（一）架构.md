# 训练
模型训练，就是要调整模型内部的参数
- 权重：输入信号的权重
- 偏置：加到加权求和结果上的一个**固定偏移量**， **调整**函数的整体输出范围，增强模型的表达能力
## 训练原理
通过梯度下降（Gradient Descent）等优化算法，反复、系统地调整模型中所有权重和偏置的数值。
- 随机设置参数
- 每轮训练，根据损失函数（错误的程度）从哪设置权重和偏置（由梯度决定）

## 单卡训练过程
- 预处理数据
- 模型送入到GPU中
- 前向传播：将一个批次的输入数据送入模型。模型根据当前的权重和偏置计算出预测结果
- 损失计算：- 将模型的预测结果与真实的标签（正确答案）一起送入损失函数。计算出一个损失值（Loss Value），表示模型这次“错”了多少。
- 反向传播：根据损失值，利用微积分的链式法则，计算出损失对模型所有参数的梯度。梯度指明了参数调整的方向和幅度。
- 参数更新：**优化器**接收梯度，并根据预设的**学习率**微调模型中所有的**权重和偏置**

## 多卡训练
### 为什么要多卡训练
**显存不够**
1. 模型参数太大
	- **模型并行**：将模型的不同层或不同部分分布到不同的 GPU 上。
2. 一次批次的数据太大
	- **数据并行**：一个大批次分成小块，分配给多张卡，每张卡只处理一小部分数据
**训练时间太长**
- 通过多卡并行计算，可以将总的计算任务并行分解
- **混合专家并行**： 模型虽然参数多但大部分是闲置专家模块的问题，用于训练超大规模（万亿级）参数模型，当数据输入时，一个门控网络（Gating Network）会决定将数据路由到哪几张卡上的专家进行计算。只有被选中的专家模块会被激活。
一般采用**数据并行 + 流水线并行 + 张量并行** 的**三维混合并行策略**
- **流水线并行**：将模型的**不同层**分配给不同的 GPU。数据在这些 GPU 之间像**流水线**一样依次流动：GPU 1 计算第 1-4 层，完成后将输出传给 GPU 2，GPU 2 计算第 5-8 层 解决模型深度的问题
- **张量并行**： 将模型某一层的**参数矩阵（如权重）**沿着行或列分割，分配给不同的 GPU。例如，将一个大矩阵乘法 Y=XA 分解为小矩阵乘法，每张卡只执行一部分计算。 
### 为什么大模型是Transfomer
1. 之前处理序列数据的是RNN等，RNN/LSTM 的核心机制是**循环**。它必须**顺序地**处理序列中的每一个词元（Token）。只有计算完第 t−1 个词元，才能开始计算第 t 个词元。这种顺序依赖性意味着**无法进行并行计算**
	- **注意力机制**允许模型同时查看序列中的所有词元，并在一步计算中完成所有词元之间的依赖关系计算， 训练计算可以完全**并行化**
2. 长距离会出现梯度消息问题
	- **注意力机制**直接建立了序列中任意两个词元之间的联系，**路径长度固定为 1**
3. 内存消耗大：RNN/LSTM 在训练时需要存储所有时间步的中间激活状态，用于反向传播，序列长度越长，内存消耗更大
	- Transformer **只需要存储当前批次和当前层的激活状态**。它不需要维护一个跨越整个序列时间步的激活历史链。


# 大模型

**稠密大模型**：输入的是稠密的张量（tensor），其中每个元素都参与模型的计算， 模型中所有的参数（权重）都会参与计算
**稀疏大模型**： 比如专家混合模型，但每次只激活一小部分